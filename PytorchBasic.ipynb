{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP729/brhI1MOf43QXMCsQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6RobinLiu/PytorchDL/blob/main/PytorchBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CGSH9hXqp57V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e031f0-c75e-4901-c97e-21d1eebe2a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor1=torch.tensor([[1,2,3],[4,5,6]])\n",
        "tensor1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N90ifeczmI7b",
        "outputId": "53566fa7-cba5-4317-df9b-9131d33badbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.arange(4)\n",
        "print(tensor.bool())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGMg19Imm4WC",
        "outputId": "cdad3708-75f2-4503-94a0-9a68331e4ddd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False,  True,  True,  True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "array=np.zeros((5,5))\n",
        "type(array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3JKtanknNHa",
        "outputId": "be6ed267-82b9-4765-8c50-bb89c61723bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.from_numpy(array)\n",
        "type(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DrELwXon6_w",
        "outputId": "1efa4014-a41b-47d3-8083-f282ee851b67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Math and Comparison"
      ],
      "metadata": {
        "id": "ruQwzubsoOUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3])\n",
        "y=torch.tensor([9,8,7])\n",
        "\n",
        "z1=x+y\n",
        "z2=x-y\n",
        "\n",
        "z=torch.true_divide(x,y)\n",
        "\n",
        "t=torch.zeros(3)\n",
        "t.add_(x)\n",
        "z1,z2,z,t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9EJgPMyoVQm",
        "outputId": "59eb2232-1ff9-4240-c717-a08691c1abbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10, 10, 10]),\n",
              " tensor([-8, -6, -4]),\n",
              " tensor([0.1111, 0.2500, 0.4286]),\n",
              " tensor([1., 2., 3.]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上面的这个加法表示原来的int类型的tensor加上浮点类型的0向量，就变成了浮点类型的tensor\n",
        "\n",
        "也就是做了一次类型转换\n",
        "\n",
        "并且使用的是add_() 也就是原地的加法   没有产生新的变量  如t=t+x\n",
        "```\n",
        "x = torch.tensor([1, 2, 3])\n",
        "t = x.float()\n",
        "\n",
        "```\n",
        "上述就是直接的类型转换\n",
        "\n",
        "- 在训练模型、调试、实验阶段  尽量不要使用原地的加法，这样兼容autograd 也不容易出bug\n",
        "- 在部署 优化  或者又大量的tensor加减中 可以使用原地的加法，加快速度\n",
        "\n",
        "下面是一个测试的例子\n",
        "\n",
        "演示了时间的快慢\n",
        "\n"
      ],
      "metadata": {
        "id": "BDh1vil2sG04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = torch.rand(10000)\n",
        "y = torch.rand(10000)\n",
        "\n",
        "# 非原地\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    z = x + y\n",
        "print(\"非原地耗时:\", time.time() - start)\n",
        "\n",
        "# 原地\n",
        "z = torch.zeros(10000)\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    z.add_(x)\n",
        "print(\"原地耗时:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrxDhmPMtIO_",
        "outputId": "f3002651-aadd-4baa-fb6d-18bdff5fb27f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "非原地耗时: 0.044324636459350586\n",
            "原地耗时: 0.028002500534057617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 指数运算\n",
        "x=torch.tensor([1,2,3])\n",
        "z1=x.pow(2)\n",
        "z2=x**2\n",
        "z1,z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4gUOdCbuJAJ",
        "outputId": "b822c912-fbcf-4e2c-8f52-8f05e06b01fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 4, 9]), tensor([1, 4, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#矩阵乘法\n",
        "x1=torch.rand((2,5))\n",
        "x2=torch.rand((5,3))\n",
        "x3=torch.mm(x1,x2)\n",
        "x3=x1.mm(x2)\n",
        "x3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qyCRf_mvtSt",
        "outputId": "dcaed43e-d7cc-48c9-ea2d-4f89159fb8f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3174, 1.3572, 2.0672],\n",
              "        [0.2600, 0.4299, 0.5847]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#矩阵乘方\n",
        "matrix=torch.rand(5,5)\n",
        "matrix.matrix_power(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1aReAlkwRbV",
        "outputId": "e5647c91-1ce8-4664-c911-553da66466f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.5382, 4.0905, 7.3241, 4.8646, 7.3105],\n",
              "        [9.2549, 4.9996, 9.0124, 5.9450, 8.9951],\n",
              "        [3.4208, 1.8763, 3.2965, 2.2322, 3.3127],\n",
              "        [6.1190, 3.2965, 6.0144, 3.8785, 5.9036],\n",
              "        [4.5084, 2.4745, 4.4193, 2.8865, 4.2907]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#依次相乘\n",
        "x1=torch.tensor([1,2,3])\n",
        "x2=torch.tensor([4,5,6])\n",
        "z=x1*x2\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TreZedoIxAPL",
        "outputId": "28ba5e7b-51da-4178-afea-baab3ae8ad40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 10, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 点积\n",
        "z=torch.dot(x1,x2)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzshCgb3xcb1",
        "outputId": "1beb149b-cc20-48da-ea2e-e57b2381d247"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 批矩阵相乘\n",
        "batch=32\n",
        "m=10\n",
        "n=20\n",
        "p=30\n",
        "\n",
        "tensor1=torch.rand((batch,m,n))\n",
        "tensor2=torch.rand((batch,n,p))\n",
        "tensor=torch.bmm(tensor1,tensor2)  # batch 乘\n",
        "tensor.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjAlfXGHz1f6",
        "outputId": "f3534b32-45a3-4e65-aee5-fbb35021a2d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Broadcasting 广播机制\n"
      ],
      "metadata": {
        "id": "WOSng-HR0xBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1=torch.rand((5,5))\n",
        "x2=torch.rand((1,5))\n",
        "\n",
        "z1=x1-x2\n",
        "z2=x1**x2\n",
        "x1,x2,z1,z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5y0AoCq00hK",
        "outputId": "f6b07fc1-007c-439d-a399-271f246587a0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.7631, 0.4519, 0.6684, 0.3246, 0.2150],\n",
              "         [0.4900, 0.1436, 0.5120, 0.7077, 0.3886],\n",
              "         [0.0078, 0.9611, 0.9459, 0.9506, 0.3970],\n",
              "         [0.4680, 0.2249, 0.1659, 0.4853, 0.1435],\n",
              "         [0.1322, 0.4653, 0.5132, 0.5227, 0.0317]]),\n",
              " tensor([[0.3453, 0.8475, 0.3269, 0.3263, 0.6010]]),\n",
              " tensor([[ 0.4178, -0.3956,  0.3415, -0.0017, -0.3860],\n",
              "         [ 0.1447, -0.7039,  0.1850,  0.3814, -0.2124],\n",
              "         [-0.3375,  0.1135,  0.6190,  0.6243, -0.2040],\n",
              "         [ 0.1227, -0.6226, -0.1611,  0.1590, -0.4575],\n",
              "         [-0.2131, -0.3823,  0.1863,  0.1964, -0.5694]]),\n",
              " tensor([[0.9109, 0.5101, 0.8766, 0.6927, 0.3970],\n",
              "         [0.7817, 0.1930, 0.8034, 0.8933, 0.5666],\n",
              "         [0.1869, 0.9669, 0.9820, 0.9836, 0.5740],\n",
              "         [0.7694, 0.2824, 0.5558, 0.7898, 0.3114],\n",
              "         [0.4973, 0.5228, 0.8041, 0.8092, 0.1255]]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里的x2实际上就是在做运算时  把每一行复制一份"
      ],
      "metadata": {
        "id": "VtG6jRHC_1V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[1,2,3],[4,5,6]])\n",
        "sum1=torch.sum(x)\n",
        "sum2=torch.sum(x,dim=0)\n",
        "sum3=torch.sum(x,dim=1)\n",
        "sum1,sum2,sum3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wT5DGKZ4HLp",
        "outputId": "13c9a084-560d-479a-c9e7-76ab0e66243b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(21), tensor([5, 7, 9]), tensor([ 6, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dim控制的是在哪个维度上聚合\n",
        "dim=0  就是沿着第0维压缩  也就是列求和\n",
        "dim=1  就是沿着第1维压缩  也就是行求和\n",
        ".....\n",
        "\n",
        "dim与tensor的维度有关\n",
        "\n",
        "$$\n",
        "-rank<=dim<rank$$\n",
        "\n",
        "若shape是(2,3,4) dim可取0,1,2,-1,-2,-3\n",
        "\n",
        "\n",
        "复数表示倒数第几个维度"
      ],
      "metadata": {
        "id": "ou-DwT3oAND5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N100AeVHACP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}